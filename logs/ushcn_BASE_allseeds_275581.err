/home/ouass/Test/MSP-IMTS/tPatchGNN/run_models.py
2025-10-31 22:49:48
run_models.py --dataset ushcn --state def --history 24 --patience 10 --batch_size 192 --lr 1e-3 --patch_size 2 --stride 2 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 32 --outlayer Linear --seed 1 --gpu 0 --epoch 1000
Namespace(multi_scales='', multi_strides='', fusion='concat', state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=2.0, stride=2.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=192, save='experiments/', load=None, seed=1, dataset='ushcn', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=32, te_dim=10, node_dim=10, gpu='0', npatch=12, device=device(type='cuda'), PID=1598272, n_months=48, pred_window=1, ndim=5)
- Epoch 000, ExpID 94774
Train - Loss (one batch): 0.69707
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86930, 0.86930, 0.93236, 0.35611, -62.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.53012, 0.53012, 0.72809, 0.32875, -59.92%
Time spent: 17.60s
- Epoch 001, ExpID 94774
Train - Loss (one batch): 0.72391
Val - Loss, MSE, RMSE, MAE, MAPE: 0.80552, 0.80552, 0.89751, 0.34737, -63.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.51781, 0.51781, 0.71959, 0.32281, -60.59%
Time spent: 11.80s
- Epoch 002, ExpID 94774
Train - Loss (one batch): 0.69584
Val - Loss, MSE, RMSE, MAE, MAPE: 0.77602, 0.77602, 0.88092, 0.33931, -60.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.51700, 0.51700, 0.71903, 0.31511, -57.76%
Time spent: 11.87s
- Epoch 003, ExpID 94774
Train - Loss (one batch): 0.46599
Val - Loss, MSE, RMSE, MAE, MAPE: 0.75298, 0.75298, 0.86774, 0.33645, -60.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.50906, 0.50906, 0.71348, 0.31371, -58.60%
Time spent: 11.67s
- Epoch 004, ExpID 94774
Train - Loss (one batch): 0.90011
Val - Loss, MSE, RMSE, MAE, MAPE: 0.73672, 0.73672, 0.85832, 0.33495, -56.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.51736, 0.51736, 0.71928, 0.31195, -54.46%
Time spent: 11.74s
- Epoch 005, ExpID 94774
Train - Loss (one batch): 0.36575
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71607, 0.71607, 0.84621, 0.33583, -58.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.50409, 0.50409, 0.71000, 0.31372, -56.70%
Time spent: 11.78s
- Epoch 006, ExpID 94774
Train - Loss (one batch): 0.33899
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70821, 0.70821, 0.84155, 0.34908, -72.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50396, 0.50396, 0.70990, 0.32627, -68.23%
Time spent: 11.97s
- Epoch 007, ExpID 94774
Train - Loss (one batch): 0.69420
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71671, 0.71671, 0.84659, 0.33890, -62.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50396, 0.50396, 0.70990, 0.32627, -68.23%
Time spent: 9.79s
- Epoch 008, ExpID 94774
Train - Loss (one batch): 0.63093
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68411, 0.68411, 0.82711, 0.35531, -70.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.50460, 0.50460, 0.71035, 0.33216, -68.59%
Time spent: 11.73s
- Epoch 009, ExpID 94774
Train - Loss (one batch): 0.68810
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70624, 0.70624, 0.84038, 0.34857, -69.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.50460, 0.50460, 0.71035, 0.33216, -68.59%
Time spent: 10.09s
- Epoch 010, ExpID 94774
Train - Loss (one batch): 0.46494
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69775, 0.69775, 0.83532, 0.33467, -60.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.50460, 0.50460, 0.71035, 0.33216, -68.59%
Time spent: 9.80s
- Epoch 011, ExpID 94774
Train - Loss (one batch): 0.48162
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69125, 0.69125, 0.83141, 0.34345, -67.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.50460, 0.50460, 0.71035, 0.33216, -68.59%
Time spent: 9.85s
- Epoch 012, ExpID 94774
Train - Loss (one batch): 0.45750
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66735, 0.66735, 0.81691, 0.34790, -71.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.49954, 0.49954, 0.70678, 0.32382, -67.32%
Time spent: 11.85s
- Epoch 013, ExpID 94774
Train - Loss (one batch): 0.50415
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68466, 0.68466, 0.82744, 0.32949, -57.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.49954, 0.49954, 0.70678, 0.32382, -67.32%
Time spent: 10.00s
- Epoch 014, ExpID 94774
Train - Loss (one batch): 0.44624
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67302, 0.67302, 0.82038, 0.32655, -54.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.49954, 0.49954, 0.70678, 0.32382, -67.32%
Time spent: 9.83s
- Epoch 015, ExpID 94774
Train - Loss (one batch): 2.03520
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66001, 0.66001, 0.81241, 0.33153, -59.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.49703, 0.49703, 0.70500, 0.30749, -54.45%
Time spent: 11.89s
- Epoch 016, ExpID 94774
Train - Loss (one batch): 0.37276
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66404, 0.66404, 0.81489, 0.32946, -59.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.49703, 0.49703, 0.70500, 0.30749, -54.45%
Time spent: 9.95s
- Epoch 017, ExpID 94774
Train - Loss (one batch): 0.33278
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65966, 0.65966, 0.81219, 0.32211, -51.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.49491, 0.49491, 0.70350, 0.29828, -48.39%
Time spent: 11.94s
- Epoch 018, ExpID 94774
Train - Loss (one batch): 0.46997
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67399, 0.67399, 0.82097, 0.33389, -60.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.49491, 0.49491, 0.70350, 0.29828, -48.39%
Time spent: 9.92s
- Epoch 019, ExpID 94774
Train - Loss (one batch): 0.26185
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66155, 0.66155, 0.81336, 0.31732, -46.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.49491, 0.49491, 0.70350, 0.29828, -48.39%
Time spent: 9.94s
- Epoch 020, ExpID 94774
Train - Loss (one batch): 0.41848
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65941, 0.65941, 0.81204, 0.32361, -57.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.49360, 0.49360, 0.70256, 0.29911, -52.88%
Time spent: 11.89s
- Epoch 021, ExpID 94774
Train - Loss (one batch): 0.51454
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64609, 0.64609, 0.80380, 0.31409, -51.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.49692, 0.49692, 0.70493, 0.29166, -46.44%
Time spent: 12.00s
- Epoch 022, ExpID 94774
Train - Loss (one batch): 0.23633
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67578, 0.67578, 0.82206, 0.32242, -52.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.49692, 0.49692, 0.70493, 0.29166, -46.44%
Time spent: 9.96s
- Epoch 023, ExpID 94774
Train - Loss (one batch): 0.23137
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63956, 0.63956, 0.79972, 0.33298, -61.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49732, 0.49732, 0.70521, 0.30973, -57.18%
Time spent: 11.91s
- Epoch 024, ExpID 94774
Train - Loss (one batch): 0.96734
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68544, 0.68544, 0.82791, 0.33461, -62.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49732, 0.49732, 0.70521, 0.30973, -57.18%
Time spent: 9.91s
- Epoch 025, ExpID 94774
Train - Loss (one batch): 0.43661
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70442, 0.70442, 0.83930, 0.32097, -57.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49732, 0.49732, 0.70521, 0.30973, -57.18%
Time spent: 9.96s
- Epoch 026, ExpID 94774
Train - Loss (one batch): 0.72447
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65636, 0.65636, 0.81016, 0.31622, -49.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49732, 0.49732, 0.70521, 0.30973, -57.18%
Time spent: 9.89s
- Epoch 027, ExpID 94774
Train - Loss (one batch): 0.44493
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66858, 0.66858, 0.81767, 0.32970, -59.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49732, 0.49732, 0.70521, 0.30973, -57.18%
Time spent: 9.92s
- Epoch 028, ExpID 94774
Train - Loss (one batch): 0.61953
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65207, 0.65207, 0.80751, 0.33224, -62.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49732, 0.49732, 0.70521, 0.30973, -57.18%
Time spent: 9.93s
- Epoch 029, ExpID 94774
Train - Loss (one batch): 0.29761
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66992, 0.66992, 0.81849, 0.31953, -53.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49732, 0.49732, 0.70521, 0.30973, -57.18%
Time spent: 9.92s
- Epoch 030, ExpID 94774
Train - Loss (one batch): 0.76429
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65215, 0.65215, 0.80756, 0.35884, -77.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49732, 0.49732, 0.70521, 0.30973, -57.18%
Time spent: 9.79s
- Epoch 031, ExpID 94774
Train - Loss (one batch): 0.50089
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68854, 0.68854, 0.82979, 0.32414, -61.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49732, 0.49732, 0.70521, 0.30973, -57.18%
Time spent: 9.81s
- Epoch 032, ExpID 94774
Train - Loss (one batch): 0.29521
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66313, 0.66313, 0.81433, 0.32045, -55.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49732, 0.49732, 0.70521, 0.30973, -57.18%
Time spent: 9.85s
- Epoch 033, ExpID 94774
Train - Loss (one batch): 0.22268
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63847, 0.63847, 0.79904, 0.31764, -52.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 33, 0.49708, 0.49708, 0.70504, 0.29484, -48.55%
Time spent: 11.85s
- Epoch 034, ExpID 94774
Train - Loss (one batch): 0.18433
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64556, 0.64556, 0.80347, 0.33284, -63.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 33, 0.49708, 0.49708, 0.70504, 0.29484, -48.55%
Time spent: 9.96s
- Epoch 035, ExpID 94774
Train - Loss (one batch): 0.28880
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65749, 0.65749, 0.81086, 0.31025, -49.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 33, 0.49708, 0.49708, 0.70504, 0.29484, -48.55%
Time spent: 9.94s
- Epoch 036, ExpID 94774
Train - Loss (one batch): 0.35808
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66885, 0.66885, 0.81783, 0.32053, -55.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 33, 0.49708, 0.49708, 0.70504, 0.29484, -48.55%
Time spent: 10.03s
- Epoch 037, ExpID 94774
Train - Loss (one batch): 0.33686
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67207, 0.67207, 0.81980, 0.32513, -57.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 33, 0.49708, 0.49708, 0.70504, 0.29484, -48.55%
Time spent: 9.95s
- Epoch 038, ExpID 94774
Train - Loss (one batch): 0.75005
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67271, 0.67271, 0.82019, 0.31907, -54.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 33, 0.49708, 0.49708, 0.70504, 0.29484, -48.55%
Time spent: 9.81s
- Epoch 039, ExpID 94774
Train - Loss (one batch): 0.41311
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69761, 0.69761, 0.83523, 0.32091, -52.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 33, 0.49708, 0.49708, 0.70504, 0.29484, -48.55%
Time spent: 9.90s
- Epoch 040, ExpID 94774
Train - Loss (one batch): 0.37951
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67566, 0.67566, 0.82199, 0.32036, -54.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 33, 0.49708, 0.49708, 0.70504, 0.29484, -48.55%
Time spent: 9.97s
- Epoch 041, ExpID 94774
Train - Loss (one batch): 0.23173
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66130, 0.66130, 0.81320, 0.33315, -61.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 33, 0.49708, 0.49708, 0.70504, 0.29484, -48.55%
Time spent: 9.89s
- Epoch 042, ExpID 94774
Train - Loss (one batch): 0.52076
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65684, 0.65684, 0.81046, 0.32765, -59.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 33, 0.49708, 0.49708, 0.70504, 0.29484, -48.55%
Time spent: 9.84s
- Epoch 043, ExpID 94774
Train - Loss (one batch): 0.64548
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67504, 0.67504, 0.82161, 0.32540, -56.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 33, 0.49708, 0.49708, 0.70504, 0.29484, -48.55%
Time spent: 9.82s
/home/ouass/Test/MSP-IMTS/tPatchGNN/run_models.py
2025-10-31 22:57:49
run_models.py --dataset ushcn --state def --history 24 --patience 10 --batch_size 192 --lr 1e-3 --patch_size 2 --stride 2 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 32 --outlayer Linear --seed 2 --gpu 0 --epoch 1000
Namespace(multi_scales='', multi_strides='', fusion='concat', state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=2.0, stride=2.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=192, save='experiments/', load=None, seed=2, dataset='ushcn', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=32, te_dim=10, node_dim=10, gpu='0', npatch=12, device=device(type='cuda'), PID=1598346, n_months=48, pred_window=1, ndim=5)
- Epoch 000, ExpID 43205
Train - Loss (one batch): 0.62929
Val - Loss, MSE, RMSE, MAE, MAPE: 0.84341, 0.84341, 0.91837, 0.34979, -64.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.51889, 0.51889, 0.72034, 0.32249, -61.11%
Time spent: 12.07s
- Epoch 001, ExpID 43205
Train - Loss (one batch): 0.82378
Val - Loss, MSE, RMSE, MAE, MAPE: 0.78709, 0.78709, 0.88718, 0.35272, -64.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.51482, 0.51482, 0.71751, 0.32838, -62.38%
Time spent: 11.68s
- Epoch 002, ExpID 43205
Train - Loss (one batch): 0.31719
Val - Loss, MSE, RMSE, MAE, MAPE: 0.77327, 0.77327, 0.87936, 0.33913, -56.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.50915, 0.50915, 0.71355, 0.31305, -53.97%
Time spent: 11.70s
- Epoch 003, ExpID 43205
Train - Loss (one batch): 0.22157
Val - Loss, MSE, RMSE, MAE, MAPE: 0.74188, 0.74188, 0.86132, 0.33937, -61.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.50651, 0.50651, 0.71170, 0.31497, -58.41%
Time spent: 11.78s
- Epoch 004, ExpID 43205
Train - Loss (one batch): 0.27973
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72155, 0.72155, 0.84944, 0.33861, -61.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.50393, 0.50393, 0.70988, 0.31489, -58.93%
Time spent: 11.68s
- Epoch 005, ExpID 43205
Train - Loss (one batch): 0.31674
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72418, 0.72418, 0.85099, 0.34465, -62.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.50393, 0.50393, 0.70988, 0.31489, -58.93%
Time spent: 9.72s
- Epoch 006, ExpID 43205
Train - Loss (one batch): 0.48920
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68972, 0.68972, 0.83050, 0.34293, -64.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50567, 0.50567, 0.71111, 0.32088, -62.12%
Time spent: 12.20s
- Epoch 007, ExpID 43205
Train - Loss (one batch): 0.39154
Val - Loss, MSE, RMSE, MAE, MAPE: 0.75643, 0.75643, 0.86973, 0.34005, -59.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50567, 0.50567, 0.71111, 0.32088, -62.12%
Time spent: 9.79s
- Epoch 008, ExpID 43205
Train - Loss (one batch): 0.56478
Val - Loss, MSE, RMSE, MAE, MAPE: 0.73172, 0.73172, 0.85540, 0.33897, -61.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50567, 0.50567, 0.71111, 0.32088, -62.12%
Time spent: 10.02s
- Epoch 009, ExpID 43205
Train - Loss (one batch): 0.53513
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72867, 0.72867, 0.85362, 0.33697, -58.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50567, 0.50567, 0.71111, 0.32088, -62.12%
Time spent: 9.71s
- Epoch 010, ExpID 43205
Train - Loss (one batch): 0.33907
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70153, 0.70153, 0.83757, 0.34744, -66.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50567, 0.50567, 0.71111, 0.32088, -62.12%
Time spent: 9.73s
- Epoch 011, ExpID 43205
Train - Loss (one batch): 0.15313
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70534, 0.70534, 0.83985, 0.35921, -73.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50567, 0.50567, 0.71111, 0.32088, -62.12%
Time spent: 9.71s
- Epoch 012, ExpID 43205
Train - Loss (one batch): 0.63955
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69867, 0.69867, 0.83586, 0.33301, -60.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50567, 0.50567, 0.71111, 0.32088, -62.12%
Time spent: 9.67s
- Epoch 013, ExpID 43205
Train - Loss (one batch): 0.50528
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69613, 0.69613, 0.83434, 0.32254, -48.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50567, 0.50567, 0.71111, 0.32088, -62.12%
Time spent: 9.63s
- Epoch 014, ExpID 43205
Train - Loss (one batch): 0.30011
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69746, 0.69746, 0.83514, 0.33964, -62.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50567, 0.50567, 0.71111, 0.32088, -62.12%
Time spent: 9.64s
- Epoch 015, ExpID 43205
Train - Loss (one batch): 0.56320
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69393, 0.69393, 0.83303, 0.33408, -59.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50567, 0.50567, 0.71111, 0.32088, -62.12%
Time spent: 9.70s
- Epoch 016, ExpID 43205
Train - Loss (one batch): 0.29059
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70019, 0.70019, 0.83678, 0.33173, -55.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50567, 0.50567, 0.71111, 0.32088, -62.12%
Time spent: 9.75s
/home/ouass/Test/MSP-IMTS/tPatchGNN/run_models.py
2025-10-31 23:00:58
run_models.py --dataset ushcn --state def --history 24 --patience 10 --batch_size 192 --lr 1e-3 --patch_size 2 --stride 2 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 32 --outlayer Linear --seed 3 --gpu 0 --epoch 1000
Namespace(multi_scales='', multi_strides='', fusion='concat', state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=2.0, stride=2.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=192, save='experiments/', load=None, seed=3, dataset='ushcn', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=32, te_dim=10, node_dim=10, gpu='0', npatch=12, device=device(type='cuda'), PID=1598401, n_months=48, pred_window=1, ndim=5)
- Epoch 000, ExpID 87894
Train - Loss (one batch): 0.50171
Val - Loss, MSE, RMSE, MAE, MAPE: 0.84631, 0.84631, 0.91995, 0.33775, -52.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.52032, 0.52032, 0.72134, 0.31133, -49.48%
Time spent: 12.01s
- Epoch 001, ExpID 87894
Train - Loss (one batch): 0.26541
Val - Loss, MSE, RMSE, MAE, MAPE: 0.81460, 0.81460, 0.90255, 0.35626, -67.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.51919, 0.51919, 0.72055, 0.32981, -62.96%
Time spent: 11.61s
- Epoch 002, ExpID 87894
Train - Loss (one batch): 0.47649
Val - Loss, MSE, RMSE, MAE, MAPE: 0.79798, 0.79798, 0.89330, 0.34157, -55.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.51430, 0.51430, 0.71715, 0.31422, -51.33%
Time spent: 11.59s
- Epoch 003, ExpID 87894
Train - Loss (one batch): 0.37178
Val - Loss, MSE, RMSE, MAE, MAPE: 0.77544, 0.77544, 0.88059, 0.34837, -62.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.51396, 0.51396, 0.71691, 0.32328, -58.02%
Time spent: 11.64s
- Epoch 004, ExpID 87894
Train - Loss (one batch): 0.20595
Val - Loss, MSE, RMSE, MAE, MAPE: 0.76263, 0.76263, 0.87329, 0.35556, -68.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.51497, 0.51497, 0.71761, 0.33051, -65.53%
Time spent: 12.08s
- Epoch 005, ExpID 87894
Train - Loss (one batch): 0.89971
Val - Loss, MSE, RMSE, MAE, MAPE: 0.74692, 0.74692, 0.86425, 0.36622, -75.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.51057, 0.51057, 0.71454, 0.34172, -71.64%
Time spent: 11.56s
- Epoch 006, ExpID 87894
Train - Loss (one batch): 0.27585
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72949, 0.72949, 0.85410, 0.33920, -59.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.50483, 0.50483, 0.71051, 0.31399, -55.59%
Time spent: 11.61s
- Epoch 007, ExpID 87894
Train - Loss (one batch): 0.21202
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72704, 0.72704, 0.85267, 0.34007, -60.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.50602, 0.50602, 0.71135, 0.31454, -55.42%
Time spent: 11.62s
- Epoch 008, ExpID 87894
Train - Loss (one batch): 0.37169
Val - Loss, MSE, RMSE, MAE, MAPE: 0.73376, 0.73376, 0.85660, 0.34223, -63.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.50602, 0.50602, 0.71135, 0.31454, -55.42%
Time spent: 9.66s
- Epoch 009, ExpID 87894
Train - Loss (one batch): 0.57466
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71976, 0.71976, 0.84838, 0.33417, -55.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.50672, 0.50672, 0.71185, 0.31025, -52.61%
Time spent: 11.60s
- Epoch 010, ExpID 87894
Train - Loss (one batch): 0.87917
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70646, 0.70646, 0.84051, 0.33669, -58.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.50804, 0.50804, 0.71277, 0.31317, -54.82%
Time spent: 11.61s
- Epoch 011, ExpID 87894
Train - Loss (one batch): 0.58049
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71217, 0.71217, 0.84390, 0.35220, -68.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.50804, 0.50804, 0.71277, 0.31317, -54.82%
Time spent: 9.63s
- Epoch 012, ExpID 87894
Train - Loss (one batch): 0.38579
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69768, 0.69768, 0.83527, 0.33723, -57.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.50563, 0.50563, 0.71108, 0.31540, -55.26%
Time spent: 11.60s
- Epoch 013, ExpID 87894
Train - Loss (one batch): 0.20975
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66958, 0.66958, 0.81828, 0.33066, -54.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.50145, 0.50145, 0.70813, 0.30826, -51.63%
Time spent: 11.80s
- Epoch 014, ExpID 87894
Train - Loss (one batch): 0.53026
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70945, 0.70945, 0.84229, 0.33956, -56.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.50145, 0.50145, 0.70813, 0.30826, -51.63%
Time spent: 9.64s
- Epoch 015, ExpID 87894
Train - Loss (one batch): 0.41361
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67281, 0.67281, 0.82025, 0.33516, -62.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.50145, 0.50145, 0.70813, 0.30826, -51.63%
Time spent: 9.68s
- Epoch 016, ExpID 87894
Train - Loss (one batch): 0.27938
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67039, 0.67039, 0.81877, 0.34685, -67.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.50145, 0.50145, 0.70813, 0.30826, -51.63%
Time spent: 9.67s
- Epoch 017, ExpID 87894
Train - Loss (one batch): 0.47922
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68859, 0.68859, 0.82981, 0.33315, -59.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.50145, 0.50145, 0.70813, 0.30826, -51.63%
Time spent: 9.67s
- Epoch 018, ExpID 87894
Train - Loss (one batch): 0.68020
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70646, 0.70646, 0.84051, 0.35621, -74.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.50145, 0.50145, 0.70813, 0.30826, -51.63%
Time spent: 9.78s
- Epoch 019, ExpID 87894
Train - Loss (one batch): 0.25941
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66690, 0.66690, 0.81664, 0.33210, -59.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.49866, 0.49866, 0.70616, 0.31044, -55.82%
Time spent: 11.86s
- Epoch 020, ExpID 87894
Train - Loss (one batch): 0.39711
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69320, 0.69320, 0.83259, 0.33479, -60.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.49866, 0.49866, 0.70616, 0.31044, -55.82%
Time spent: 9.91s
- Epoch 021, ExpID 87894
Train - Loss (one batch): 0.24684
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69782, 0.69782, 0.83536, 0.34734, -71.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.49866, 0.49866, 0.70616, 0.31044, -55.82%
Time spent: 9.72s
- Epoch 022, ExpID 87894
Train - Loss (one batch): 0.38173
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67238, 0.67238, 0.81999, 0.34121, -65.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.49866, 0.49866, 0.70616, 0.31044, -55.82%
Time spent: 9.72s
- Epoch 023, ExpID 87894
Train - Loss (one batch): 0.22792
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67866, 0.67866, 0.82381, 0.33675, -56.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.49866, 0.49866, 0.70616, 0.31044, -55.82%
Time spent: 9.80s
- Epoch 024, ExpID 87894
Train - Loss (one batch): 0.42198
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68772, 0.68772, 0.82929, 0.32244, -53.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.49866, 0.49866, 0.70616, 0.31044, -55.82%
Time spent: 10.05s
- Epoch 025, ExpID 87894
Train - Loss (one batch): 1.12520
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67328, 0.67328, 0.82053, 0.34661, -70.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.49866, 0.49866, 0.70616, 0.31044, -55.82%
Time spent: 9.80s
- Epoch 026, ExpID 87894
Train - Loss (one batch): 0.31934
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66662, 0.66662, 0.81647, 0.32145, -53.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.49968, 0.49968, 0.70688, 0.29830, -49.07%
Time spent: 11.60s
- Epoch 027, ExpID 87894
Train - Loss (one batch): 0.45117
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67647, 0.67647, 0.82248, 0.32670, -54.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.49968, 0.49968, 0.70688, 0.29830, -49.07%
Time spent: 9.70s
- Epoch 028, ExpID 87894
Train - Loss (one batch): 0.71892
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67354, 0.67354, 0.82070, 0.33281, -58.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.49968, 0.49968, 0.70688, 0.29830, -49.07%
Time spent: 9.69s
- Epoch 029, ExpID 87894
Train - Loss (one batch): 0.43300
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67078, 0.67078, 0.81901, 0.33743, -63.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.49968, 0.49968, 0.70688, 0.29830, -49.07%
Time spent: 9.69s
- Epoch 030, ExpID 87894
Train - Loss (one batch): 0.51784
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67582, 0.67582, 0.82209, 0.32431, -52.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.49968, 0.49968, 0.70688, 0.29830, -49.07%
Time spent: 9.69s
- Epoch 031, ExpID 87894
Train - Loss (one batch): 0.41526
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67531, 0.67531, 0.82177, 0.33961, -65.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.49968, 0.49968, 0.70688, 0.29830, -49.07%
Time spent: 9.78s
- Epoch 032, ExpID 87894
Train - Loss (one batch): 0.64013
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65094, 0.65094, 0.80681, 0.32955, -59.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 32, 0.49794, 0.49794, 0.70565, 0.30619, -54.73%
Time spent: 11.63s
- Epoch 033, ExpID 87894
Train - Loss (one batch): 0.45354
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68789, 0.68789, 0.82939, 0.33678, -63.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 32, 0.49794, 0.49794, 0.70565, 0.30619, -54.73%
Time spent: 9.64s
- Epoch 034, ExpID 87894
Train - Loss (one batch): 0.42206
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64185, 0.64185, 0.80116, 0.34121, -68.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.50247, 0.50247, 0.70885, 0.31828, -63.51%
Time spent: 11.61s
- Epoch 035, ExpID 87894
Train - Loss (one batch): 0.55042
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63235, 0.63235, 0.79520, 0.32939, -60.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 35, 0.50172, 0.50172, 0.70832, 0.30760, -55.89%
Time spent: 11.62s
- Epoch 036, ExpID 87894
Train - Loss (one batch): 0.60225
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66297, 0.66297, 0.81423, 0.31444, -49.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 35, 0.50172, 0.50172, 0.70832, 0.30760, -55.89%
Time spent: 9.81s
- Epoch 037, ExpID 87894
Train - Loss (one batch): 0.45702
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65194, 0.65194, 0.80743, 0.34720, -68.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 35, 0.50172, 0.50172, 0.70832, 0.30760, -55.89%
Time spent: 9.59s
- Epoch 038, ExpID 87894
Train - Loss (one batch): 0.39843
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67551, 0.67551, 0.82189, 0.32136, -53.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 35, 0.50172, 0.50172, 0.70832, 0.30760, -55.89%
Time spent: 9.74s
- Epoch 039, ExpID 87894
Train - Loss (one batch): 0.66477
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65320, 0.65320, 0.80821, 0.32612, -54.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 35, 0.50172, 0.50172, 0.70832, 0.30760, -55.89%
Time spent: 9.61s
- Epoch 040, ExpID 87894
Train - Loss (one batch): 0.16428
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63815, 0.63815, 0.79884, 0.32936, -58.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 35, 0.50172, 0.50172, 0.70832, 0.30760, -55.89%
Time spent: 9.63s
- Epoch 041, ExpID 87894
Train - Loss (one batch): 0.30408
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68644, 0.68644, 0.82852, 0.31909, -52.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 35, 0.50172, 0.50172, 0.70832, 0.30760, -55.89%
Time spent: 9.63s
- Epoch 042, ExpID 87894
Train - Loss (one batch): 0.61596
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63346, 0.63346, 0.79590, 0.32229, -53.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 35, 0.50172, 0.50172, 0.70832, 0.30760, -55.89%
Time spent: 9.62s
- Epoch 043, ExpID 87894
Train - Loss (one batch): 0.75408
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66786, 0.66786, 0.81723, 0.34278, -66.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 35, 0.50172, 0.50172, 0.70832, 0.30760, -55.89%
Time spent: 9.98s
- Epoch 044, ExpID 87894
Train - Loss (one batch): 0.36281
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69246, 0.69246, 0.83214, 0.34436, -66.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 35, 0.50172, 0.50172, 0.70832, 0.30760, -55.89%
Time spent: 9.80s
- Epoch 045, ExpID 87894
Train - Loss (one batch): 0.18614
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65747, 0.65747, 0.81084, 0.31782, -54.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 35, 0.50172, 0.50172, 0.70832, 0.30760, -55.89%
Time spent: 9.74s
/home/ouass/Test/MSP-IMTS/tPatchGNN/run_models.py
2025-10-31 23:09:08
run_models.py --dataset ushcn --state def --history 24 --patience 10 --batch_size 192 --lr 1e-3 --patch_size 2 --stride 2 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 32 --outlayer Linear --seed 4 --gpu 0 --epoch 1000
Namespace(multi_scales='', multi_strides='', fusion='concat', state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=2.0, stride=2.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=192, save='experiments/', load=None, seed=4, dataset='ushcn', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=32, te_dim=10, node_dim=10, gpu='0', npatch=12, device=device(type='cuda'), PID=1598476, n_months=48, pred_window=1, ndim=5)
- Epoch 000, ExpID 21177
Train - Loss (one batch): 0.44799
Val - Loss, MSE, RMSE, MAE, MAPE: 0.83937, 0.83937, 0.91617, 0.33787, -48.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.53133, 0.53133, 0.72892, 0.31296, -46.80%
Time spent: 12.55s
- Epoch 001, ExpID 21177
Train - Loss (one batch): 0.27068
Val - Loss, MSE, RMSE, MAE, MAPE: 0.84565, 0.84565, 0.91959, 0.35196, -51.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.53133, 0.53133, 0.72892, 0.31296, -46.80%
Time spent: 9.86s
- Epoch 002, ExpID 21177
Train - Loss (one batch): 0.43248
Val - Loss, MSE, RMSE, MAE, MAPE: 0.76977, 0.76977, 0.87736, 0.33341, -52.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.51405, 0.51405, 0.71698, 0.30830, -48.98%
Time spent: 12.11s
- Epoch 003, ExpID 21177
Train - Loss (one batch): 0.52384
Val - Loss, MSE, RMSE, MAE, MAPE: 0.74256, 0.74256, 0.86172, 0.33919, -55.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.51557, 0.51557, 0.71803, 0.31516, -53.23%
Time spent: 11.77s
- Epoch 004, ExpID 21177
Train - Loss (one batch): 0.64942
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72724, 0.72724, 0.85278, 0.34218, -56.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.51241, 0.51241, 0.71583, 0.31776, -53.86%
Time spent: 11.78s
- Epoch 005, ExpID 21177
Train - Loss (one batch): 0.35807
Val - Loss, MSE, RMSE, MAE, MAPE: 0.75375, 0.75375, 0.86819, 0.33982, -51.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.51241, 0.51241, 0.71583, 0.31776, -53.86%
Time spent: 9.90s
- Epoch 006, ExpID 21177
Train - Loss (one batch): 0.55614
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70948, 0.70948, 0.84231, 0.34285, -60.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.51693, 0.51693, 0.71898, 0.32059, -58.18%
Time spent: 11.91s
- Epoch 007, ExpID 21177
Train - Loss (one batch): 0.25682
Val - Loss, MSE, RMSE, MAE, MAPE: 0.74876, 0.74876, 0.86531, 0.32670, -51.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.51693, 0.51693, 0.71898, 0.32059, -58.18%
Time spent: 9.81s
- Epoch 008, ExpID 21177
Train - Loss (one batch): 0.60689
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72137, 0.72137, 0.84933, 0.34034, -59.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.51693, 0.51693, 0.71898, 0.32059, -58.18%
Time spent: 9.92s
- Epoch 009, ExpID 21177
Train - Loss (one batch): 0.37566
Val - Loss, MSE, RMSE, MAE, MAPE: 0.73588, 0.73588, 0.85784, 0.34464, -59.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.51693, 0.51693, 0.71898, 0.32059, -58.18%
Time spent: 9.81s
- Epoch 010, ExpID 21177
Train - Loss (one batch): 1.02655
Val - Loss, MSE, RMSE, MAE, MAPE: 0.74018, 0.74018, 0.86034, 0.35644, -66.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.51693, 0.51693, 0.71898, 0.32059, -58.18%
Time spent: 9.96s
- Epoch 011, ExpID 21177
Train - Loss (one batch): 0.29029
Val - Loss, MSE, RMSE, MAE, MAPE: 0.75142, 0.75142, 0.86684, 0.33995, -56.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.51693, 0.51693, 0.71898, 0.32059, -58.18%
Time spent: 9.87s
- Epoch 012, ExpID 21177
Train - Loss (one batch): 0.55376
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70880, 0.70880, 0.84190, 0.33402, -57.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.50458, 0.50458, 0.71034, 0.30994, -54.51%
Time spent: 12.04s
- Epoch 013, ExpID 21177
Train - Loss (one batch): 0.30767
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71271, 0.71271, 0.84422, 0.34131, -61.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.50458, 0.50458, 0.71034, 0.30994, -54.51%
Time spent: 9.94s
- Epoch 014, ExpID 21177
Train - Loss (one batch): 0.47238
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72869, 0.72869, 0.85363, 0.33693, -59.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.50458, 0.50458, 0.71034, 0.30994, -54.51%
Time spent: 10.01s
- Epoch 015, ExpID 21177
Train - Loss (one batch): 0.34694
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71626, 0.71626, 0.84632, 0.34161, -61.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.50458, 0.50458, 0.71034, 0.30994, -54.51%
Time spent: 10.25s
- Epoch 016, ExpID 21177
Train - Loss (one batch): 0.40187
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69924, 0.69924, 0.83621, 0.34847, -64.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51093, 0.51093, 0.71480, 0.32452, -60.77%
Time spent: 11.87s
- Epoch 017, ExpID 21177
Train - Loss (one batch): 0.42923
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72646, 0.72646, 0.85232, 0.32043, -51.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51093, 0.51093, 0.71480, 0.32452, -60.77%
Time spent: 9.94s
- Epoch 018, ExpID 21177
Train - Loss (one batch): 0.26232
Val - Loss, MSE, RMSE, MAE, MAPE: 0.73174, 0.73174, 0.85542, 0.33811, -60.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51093, 0.51093, 0.71480, 0.32452, -60.77%
Time spent: 9.85s
- Epoch 019, ExpID 21177
Train - Loss (one batch): 0.53975
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72248, 0.72248, 0.84999, 0.32153, -48.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51093, 0.51093, 0.71480, 0.32452, -60.77%
Time spent: 9.86s
- Epoch 020, ExpID 21177
Train - Loss (one batch): 0.51887
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70481, 0.70481, 0.83953, 0.33372, -58.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51093, 0.51093, 0.71480, 0.32452, -60.77%
Time spent: 9.96s
- Epoch 021, ExpID 21177
Train - Loss (one batch): 0.39283
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71473, 0.71473, 0.84542, 0.32773, -51.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51093, 0.51093, 0.71480, 0.32452, -60.77%
Time spent: 10.24s
- Epoch 022, ExpID 21177
Train - Loss (one batch): 0.34506
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71645, 0.71645, 0.84643, 0.33327, -59.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51093, 0.51093, 0.71480, 0.32452, -60.77%
Time spent: 9.89s
- Epoch 023, ExpID 21177
Train - Loss (one batch): 0.48719
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71131, 0.71131, 0.84339, 0.32003, -51.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51093, 0.51093, 0.71480, 0.32452, -60.77%
Time spent: 9.93s
- Epoch 024, ExpID 21177
Train - Loss (one batch): 0.20067
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72155, 0.72155, 0.84944, 0.32373, -54.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51093, 0.51093, 0.71480, 0.32452, -60.77%
Time spent: 9.80s
- Epoch 025, ExpID 21177
Train - Loss (one batch): 0.44749
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72105, 0.72105, 0.84915, 0.32847, -56.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51093, 0.51093, 0.71480, 0.32452, -60.77%
Time spent: 9.78s
- Epoch 026, ExpID 21177
Train - Loss (one batch): 0.23189
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71997, 0.71997, 0.84851, 0.32569, -53.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51093, 0.51093, 0.71480, 0.32452, -60.77%
Time spent: 9.76s
/home/ouass/Test/MSP-IMTS/tPatchGNN/run_models.py
2025-10-31 23:14:01
run_models.py --dataset ushcn --state def --history 24 --patience 10 --batch_size 192 --lr 1e-3 --patch_size 2 --stride 2 --nhead 1 --tf_layer 1 --nlayer 1 --te_dim 10 --node_dim 10 --hid_dim 32 --outlayer Linear --seed 5 --gpu 0 --epoch 1000
Namespace(multi_scales='', multi_strides='', fusion='concat', state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=1, epoch=1000, patience=10, history=24, patch_size=2.0, stride=2.0, logmode='a', lr=0.001, w_decay=0.0, batch_size=192, save='experiments/', load=None, seed=5, dataset='ushcn', quantization=0.0, model='tPatchGNN', outlayer='Linear', hid_dim=32, te_dim=10, node_dim=10, gpu='0', npatch=12, device=device(type='cuda'), PID=1598519, n_months=48, pred_window=1, ndim=5)
- Epoch 000, ExpID 55739
Train - Loss (one batch): 0.49047
Val - Loss, MSE, RMSE, MAE, MAPE: 0.84578, 0.84578, 0.91966, 0.35667, -62.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.53168, 0.53168, 0.72916, 0.32865, -61.76%
Time spent: 12.19s
- Epoch 001, ExpID 55739
Train - Loss (one batch): 0.56357
Val - Loss, MSE, RMSE, MAE, MAPE: 0.82309, 0.82309, 0.90724, 0.34534, -58.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.52119, 0.52119, 0.72194, 0.31859, -56.49%
Time spent: 11.91s
- Epoch 002, ExpID 55739
Train - Loss (one batch): 0.29499
Val - Loss, MSE, RMSE, MAE, MAPE: 0.81091, 0.81091, 0.90050, 0.34116, -58.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.52260, 0.52260, 0.72291, 0.31590, -56.39%
Time spent: 11.84s
- Epoch 003, ExpID 55739
Train - Loss (one batch): 0.50156
Val - Loss, MSE, RMSE, MAE, MAPE: 0.78479, 0.78479, 0.88588, 0.35412, -68.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.51545, 0.51545, 0.71795, 0.32898, -67.30%
Time spent: 11.81s
- Epoch 004, ExpID 55739
Train - Loss (one batch): 0.61840
Val - Loss, MSE, RMSE, MAE, MAPE: 0.77315, 0.77315, 0.87929, 0.34007, -58.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.51762, 0.51762, 0.71946, 0.31484, -56.54%
Time spent: 12.05s
- Epoch 005, ExpID 55739
Train - Loss (one batch): 0.27481
Val - Loss, MSE, RMSE, MAE, MAPE: 0.76170, 0.76170, 0.87275, 0.33580, -57.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.51114, 0.51114, 0.71494, 0.30961, -54.69%
Time spent: 11.76s
- Epoch 006, ExpID 55739
Train - Loss (one batch): 0.40308
Val - Loss, MSE, RMSE, MAE, MAPE: 0.75301, 0.75301, 0.86776, 0.34737, -65.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.51177, 0.51177, 0.71538, 0.32207, -62.10%
Time spent: 11.82s
- Epoch 007, ExpID 55739
Train - Loss (one batch): 0.59860
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72569, 0.72569, 0.85187, 0.33571, -60.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.50800, 0.50800, 0.71274, 0.31071, -57.65%
Time spent: 11.75s
- Epoch 008, ExpID 55739
Train - Loss (one batch): 0.40738
Val - Loss, MSE, RMSE, MAE, MAPE: 0.74590, 0.74590, 0.86365, 0.33946, -63.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.50800, 0.50800, 0.71274, 0.31071, -57.65%
Time spent: 9.93s
- Epoch 009, ExpID 55739
Train - Loss (one batch): 0.42644
Val - Loss, MSE, RMSE, MAE, MAPE: 0.74256, 0.74256, 0.86172, 0.33744, -59.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.50800, 0.50800, 0.71274, 0.31071, -57.65%
Time spent: 9.93s
- Epoch 010, ExpID 55739
Train - Loss (one batch): 0.95175
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72446, 0.72446, 0.85115, 0.35159, -64.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.50782, 0.50782, 0.71262, 0.32859, -62.69%
Time spent: 11.85s
- Epoch 011, ExpID 55739
Train - Loss (one batch): 0.33296
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71882, 0.71882, 0.84783, 0.33458, -58.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.50483, 0.50483, 0.71052, 0.31054, -54.57%
Time spent: 11.79s
- Epoch 012, ExpID 55739
Train - Loss (one batch): 0.28251
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71268, 0.71268, 0.84421, 0.32963, -56.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.50449, 0.50449, 0.71027, 0.30643, -52.76%
Time spent: 11.75s
- Epoch 013, ExpID 55739
Train - Loss (one batch): 0.76111
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69088, 0.69088, 0.83119, 0.33174, -58.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.50205, 0.50205, 0.70856, 0.30767, -54.56%
Time spent: 11.80s
- Epoch 014, ExpID 55739
Train - Loss (one batch): 0.74473
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71752, 0.71752, 0.84706, 0.33580, -60.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.50205, 0.50205, 0.70856, 0.30767, -54.56%
Time spent: 9.83s
- Epoch 015, ExpID 55739
Train - Loss (one batch): 0.25671
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69897, 0.69897, 0.83604, 0.33104, -59.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.50205, 0.50205, 0.70856, 0.30767, -54.56%
Time spent: 9.80s
- Epoch 016, ExpID 55739
Train - Loss (one batch): 0.23635
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68827, 0.68827, 0.82962, 0.32552, -55.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.50246, 0.50246, 0.70884, 0.30213, -51.80%
Time spent: 11.79s
- Epoch 017, ExpID 55739
Train - Loss (one batch): 0.43794
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68762, 0.68762, 0.82923, 0.33795, -64.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.50263, 0.50263, 0.70897, 0.31478, -60.66%
Time spent: 12.19s
- Epoch 018, ExpID 55739
Train - Loss (one batch): 0.70607
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69076, 0.69076, 0.83112, 0.36835, -81.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.50263, 0.50263, 0.70897, 0.31478, -60.66%
Time spent: 9.78s
- Epoch 019, ExpID 55739
Train - Loss (one batch): 0.44194
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69158, 0.69158, 0.83162, 0.32846, -53.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.50263, 0.50263, 0.70897, 0.31478, -60.66%
Time spent: 9.85s
- Epoch 020, ExpID 55739
Train - Loss (one batch): 0.26956
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69282, 0.69282, 0.83236, 0.32763, -57.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.50263, 0.50263, 0.70897, 0.31478, -60.66%
Time spent: 9.74s
- Epoch 021, ExpID 55739
Train - Loss (one batch): 0.39744
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68314, 0.68314, 0.82652, 0.34051, -67.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.50274, 0.50274, 0.70904, 0.31852, -64.30%
Time spent: 11.80s
- Epoch 022, ExpID 55739
Train - Loss (one batch): 0.27952
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68319, 0.68319, 0.82655, 0.33005, -54.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.50274, 0.50274, 0.70904, 0.31852, -64.30%
Time spent: 9.82s
- Epoch 023, ExpID 55739
Train - Loss (one batch): 0.61320
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65766, 0.65766, 0.81096, 0.34192, -64.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49992, 0.49992, 0.70705, 0.32013, -62.17%
Time spent: 11.90s
- Epoch 024, ExpID 55739
Train - Loss (one batch): 0.24852
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66148, 0.66148, 0.81332, 0.32708, -56.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49992, 0.49992, 0.70705, 0.32013, -62.17%
Time spent: 9.89s
- Epoch 025, ExpID 55739
Train - Loss (one batch): 0.85051
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69240, 0.69240, 0.83211, 0.33312, -60.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49992, 0.49992, 0.70705, 0.32013, -62.17%
Time spent: 9.82s
- Epoch 026, ExpID 55739
Train - Loss (one batch): 0.53654
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67203, 0.67203, 0.81977, 0.33546, -63.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49992, 0.49992, 0.70705, 0.32013, -62.17%
Time spent: 9.81s
- Epoch 027, ExpID 55739
Train - Loss (one batch): 0.42290
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68589, 0.68589, 0.82819, 0.31643, -48.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 23, 0.49992, 0.49992, 0.70705, 0.32013, -62.17%
Time spent: 9.89s
- Epoch 028, ExpID 55739
Train - Loss (one batch): 0.29914
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65493, 0.65493, 0.80928, 0.32913, -58.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.49764, 0.49764, 0.70544, 0.30549, -53.77%
Time spent: 11.91s
- Epoch 029, ExpID 55739
Train - Loss (one batch): 1.28427
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65462, 0.65462, 0.80908, 0.35037, -71.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.50790, 0.50790, 0.71267, 0.32712, -66.79%
Time spent: 12.23s
- Epoch 030, ExpID 55739
Train - Loss (one batch): 0.44380
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66321, 0.66321, 0.81438, 0.32860, -57.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 29, 0.50790, 0.50790, 0.71267, 0.32712, -66.79%
Time spent: 9.90s
- Epoch 031, ExpID 55739
Train - Loss (one batch): 0.48687
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65426, 0.65426, 0.80887, 0.31703, -49.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.49459, 0.49459, 0.70327, 0.29455, -46.28%
Time spent: 11.71s
- Epoch 032, ExpID 55739
Train - Loss (one batch): 0.23292
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68875, 0.68875, 0.82991, 0.31153, -43.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.49459, 0.49459, 0.70327, 0.29455, -46.28%
Time spent: 9.86s
- Epoch 033, ExpID 55739
Train - Loss (one batch): 0.47216
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68023, 0.68023, 0.82476, 0.31491, -46.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.49459, 0.49459, 0.70327, 0.29455, -46.28%
Time spent: 10.03s
- Epoch 034, ExpID 55739
Train - Loss (one batch): 0.48937
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69445, 0.69445, 0.83334, 0.32402, -48.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.49459, 0.49459, 0.70327, 0.29455, -46.28%
Time spent: 9.76s
- Epoch 035, ExpID 55739
Train - Loss (one batch): 0.20313
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66046, 0.66046, 0.81269, 0.32449, -55.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.49459, 0.49459, 0.70327, 0.29455, -46.28%
Time spent: 9.80s
- Epoch 036, ExpID 55739
Train - Loss (one batch): 0.59592
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66845, 0.66845, 0.81759, 0.33375, -61.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.49459, 0.49459, 0.70327, 0.29455, -46.28%
Time spent: 9.72s
- Epoch 037, ExpID 55739
Train - Loss (one batch): 0.52601
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67357, 0.67357, 0.82071, 0.32616, -55.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.49459, 0.49459, 0.70327, 0.29455, -46.28%
Time spent: 9.74s
- Epoch 038, ExpID 55739
Train - Loss (one batch): 0.51971
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70257, 0.70257, 0.83819, 0.32794, -54.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.49459, 0.49459, 0.70327, 0.29455, -46.28%
Time spent: 9.73s
- Epoch 039, ExpID 55739
Train - Loss (one batch): 0.24624
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69258, 0.69258, 0.83221, 0.32446, -46.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.49459, 0.49459, 0.70327, 0.29455, -46.28%
Time spent: 9.76s
- Epoch 040, ExpID 55739
Train - Loss (one batch): 0.29784
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64542, 0.64542, 0.80338, 0.31671, -46.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.49795, 0.49795, 0.70566, 0.29462, -43.76%
Time spent: 11.64s
- Epoch 041, ExpID 55739
Train - Loss (one batch): 0.45751
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68251, 0.68251, 0.82614, 0.32765, -58.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.49795, 0.49795, 0.70566, 0.29462, -43.76%
Time spent: 9.67s
- Epoch 042, ExpID 55739
Train - Loss (one batch): 0.54257
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66582, 0.66582, 0.81598, 0.33332, -65.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.49795, 0.49795, 0.70566, 0.29462, -43.76%
Time spent: 9.68s
- Epoch 043, ExpID 55739
Train - Loss (one batch): 0.37831
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66108, 0.66108, 0.81307, 0.33601, -64.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.49795, 0.49795, 0.70566, 0.29462, -43.76%
Time spent: 10.05s
- Epoch 044, ExpID 55739
Train - Loss (one batch): 0.25110
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68799, 0.68799, 0.82945, 0.36530, -70.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.49795, 0.49795, 0.70566, 0.29462, -43.76%
Time spent: 9.76s
- Epoch 045, ExpID 55739
Train - Loss (one batch): 0.48195
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68187, 0.68187, 0.82575, 0.32633, -56.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.49795, 0.49795, 0.70566, 0.29462, -43.76%
Time spent: 9.73s
- Epoch 046, ExpID 55739
Train - Loss (one batch): 0.23753
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68215, 0.68215, 0.82593, 0.32198, -51.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.49795, 0.49795, 0.70566, 0.29462, -43.76%
Time spent: 9.80s
- Epoch 047, ExpID 55739
Train - Loss (one batch): 0.24201
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70897, 0.70897, 0.84200, 0.32538, -56.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.49795, 0.49795, 0.70566, 0.29462, -43.76%
Time spent: 9.72s
- Epoch 048, ExpID 55739
Train - Loss (one batch): 0.25289
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67918, 0.67918, 0.82412, 0.31387, -48.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.49795, 0.49795, 0.70566, 0.29462, -43.76%
Time spent: 9.87s
- Epoch 049, ExpID 55739
Train - Loss (one batch): 0.39839
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67946, 0.67946, 0.82429, 0.31427, -44.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.49795, 0.49795, 0.70566, 0.29462, -43.76%
Time spent: 9.92s
- Epoch 050, ExpID 55739
Train - Loss (one batch): 0.57356
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68922, 0.68922, 0.83019, 0.32501, -54.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.49795, 0.49795, 0.70566, 0.29462, -43.76%
Time spent: 10.05s
